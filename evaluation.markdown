---
layout: page
title: Evaluation
permalink: /Evaluation/
---

# Metrics

We will evaluate the performance of `cuneiform/transcription/Sumerian-to-English` machine
translation model. The scorers employed for EvaCun 2023 are based on BLEU.  

Each participating team will initially have access only to the training data.  
Later, test data
containing only cuneiform and transcribed texts will also be released.  

The BLEU metrics measures machine translation quality by word-level n-grams. It is a
modified version of the sacreBLEU 1 , which provides hassle-free computation of shareable,
comparable, and reproducible BLEU scores.

# Baselines

We will use the results from the paper “Translating Akkadian to English with Neural
Machine Translation” (in Press) as baseline.